{
 "cells": [
  {
   "attachments": {
    "ibm-cloud.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ibm-cloud.png](attachment:ibm-cloud.png)\n",
    "\n",
    "## CASE STUDY - Deploying a recommender\n",
    "\n",
    "For this lab we will be using the MovieLens data :\n",
    "\n",
    "* [MovieLens Downloads](https://grouplens.org/datasets/movielens/latest/)\n",
    "\n",
    "download either **ml-latest-small.zip** or **ml-latest.zip** from this link and add the unziped folder to the data folder of the lab directory. We recommend you to use the small version if you are not working with a Spark cluster or a High memory machine.\n",
    "\n",
    "The two important pages for documentation are below.\n",
    "\n",
    "* [Spark MLlib collaborative filtering docs](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html) \n",
    "* [Spark ALS docs](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.ALS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark as ps\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "DATA_DIR = os.path.join(\"..\", \"data\")\n",
    "SAVE_DIR = os.path.join(\"..\", \"saved-recommender\")\n",
    "\n",
    "if os.path.isdir(SAVE_DIR):\n",
    "    shutil.rmtree(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.1\n"
     ]
    }
   ],
   "source": [
    "## ensure the spark context is available\n",
    "spark = (ps.sql.SparkSession.builder\n",
    "        .appName(\"sandbox\")\n",
    "        .getOrCreate()\n",
    "        )\n",
    "\n",
    "sc = spark.sparkContext\n",
    "print(spark.version) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure the data are downloaded, unziped and placed in the data folder of this lab.\n",
    "\n",
    "The data can be downloaded <a href=\"https://grouplens.org/datasets/movielens/\">here</a>. We recommend you to download the small version: <b>ml-latest-small.zip</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR make sure the path to the Movie Lens data is correct\n"
     ]
    }
   ],
   "source": [
    "movielens_data_dir = os.path.join(DATA_DIR, \"ml-latest-small\")        \n",
    "if not os.path.exists(movielens_data_dir):\n",
    "    print(\"ERROR make sure the path to the Movie Lens data is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+---------+\n",
      "|user_id|movie_id|rating|timestamp|\n",
      "+-------+--------+------+---------+\n",
      "|      1|       1|   4.0|964982703|\n",
      "|      1|       3|   4.0|964981247|\n",
      "|      1|       6|   4.0|964982224|\n",
      "|      1|      47|   5.0|964983815|\n",
      "+-------+--------+------+---------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## load the ratings data as a pysaprk dataframe\n",
    "ratings_file = os.path.join(movielens_data_dir, \"ratings.csv\")\n",
    "df = spark.read.format(\"csv\").options(header=\"true\", inferSchema=\"true\").load(ratings_file)\n",
    "df = df.withColumnRenamed(\"movieID\", \"movie_id\")\n",
    "df = df.withColumnRenamed(\"userID\", \"user_id\")\n",
    "df.show(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|               title|              genres|\n",
      "+--------+--------------------+--------------------+\n",
      "|       1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|       2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|       3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|       4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## load the movies data as a pyspark dataframe\n",
    "movies_file = os.path.join(movielens_data_dir, \"movies.csv\") \n",
    "movies_df = spark.read.format(\"csv\").options(header=\"true\", inferSchema=\"true\").load(movies_file)\n",
    "movies_df = movies_df.withColumnRenamed(\"movieID\", \"movie_id\")\n",
    "movies_df.show(n=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 1\n",
    "\n",
    "Explore the movie lens data a little and summarize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------------+------------------+--------------------+\n",
      "|summary|           user_id|        movie_id|            rating|           timestamp|\n",
      "+-------+------------------+----------------+------------------+--------------------+\n",
      "|  count|            100836|          100836|            100836|              100836|\n",
      "|   mean|326.12756356856676|19435.2957177992| 3.501556983616962|1.2059460873684695E9|\n",
      "| stddev| 182.6184914635004|35530.9871987003|1.0425292390606342|2.1626103599513078E8|\n",
      "|    min|                 1|               1|               0.5|           828124615|\n",
      "|    max|               610|          193609|               5.0|          1537799250|\n",
      "+-------+------------------+----------------+------------------+--------------------+\n",
      "\n",
      "Unique users: 610\n",
      "Unique movies: 9724\n",
      "Movies with Rating > 2: 8852\n",
      "Movies with Rating > 3: 7363\n",
      "Movies with Rating > 4: 4056\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE (summarize the data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 2\n",
    "\n",
    "Find the ten most popular movies. \n",
    "\n",
    "\n",
    "1. Create 2 pyspark dataframes one with the count of each film in df and one with the average rating of each movie in df.\n",
    "2. Join these two dataframes in a third dataframe. Then, filter this dataframe to select only the movies that have been seen more than 100 times.\n",
    "3. Use the movies_df dataframe to add the names of each movies on the dataframe created in 2. Then, order the dataframe by descending average rating.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----+--------------------+--------------------+\n",
      "|movie_id|      avg(rating)|count|               title|              genres|\n",
      "+--------+-----------------+-----+--------------------+--------------------+\n",
      "|     318|4.429022082018927|  317|Shawshank Redempt...|         Crime|Drama|\n",
      "|     858|        4.2890625|  192|Godfather, The (1...|         Crime|Drama|\n",
      "|    2959|4.272935779816514|  218|   Fight Club (1999)|Action|Crime|Dram...|\n",
      "|    1221| 4.25968992248062|  129|Godfather: Part I...|         Crime|Drama|\n",
      "|   48516|4.252336448598131|  107|Departed, The (2006)|Crime|Drama|Thriller|\n",
      "|    1213|             4.25|  126|   Goodfellas (1990)|         Crime|Drama|\n",
      "|   58559|4.238255033557047|  149|Dark Knight, The ...|Action|Crime|Dram...|\n",
      "|      50|4.237745098039215|  204|Usual Suspects, T...|Crime|Mystery|Thr...|\n",
      "|    1197|4.232394366197183|  142|Princess Bride, T...|Action|Adventure|...|\n",
      "|     260|4.231075697211155|  251|Star Wars: Episod...|Action|Adventure|...|\n",
      "+--------+-----------------+-----+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE (Replace the symbole #<> with your code)\n",
    "\n",
    "## 1_\n",
    "movie_counts = #<>\n",
    "top_rated = #<>\n",
    "\n",
    "## 2_\n",
    "top_movies = #<>\n",
    "\n",
    "## 3_\n",
    "top_movies = #<>\n",
    "\n",
    "\n",
    "top_movies.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 3\n",
    "\n",
    "We will now fit a ALS model, this is matrix factorization model used for rating recommendation. See the [Spark ALS docs](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.ALS)\n",
    "for example usage. \n",
    "\n",
    "First we split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function called **train_model()** that takes two inputs :\n",
    "\n",
    "1. ``reg_param`` : the regularization parameter of the factorization model\n",
    "2. ``implicit_prefs`` : a boolean variable that indicate whereas the model should used explicit or implicit ratings.\n",
    "    \n",
    "The function train an ALS model on the training set then predict the test set and evaluate this prediction.\n",
    "The output of the function should be the RMSE of the fitted model on the test set./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (Replace the symbole #<> with your code)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "\n",
    "def train_model(reg_param, implicit_prefs=False):\n",
    "    \"\"\"\n",
    "    Train and evaluate an ALS model\n",
    "    Inputs : the regularization parametre of the ALS model and the implicit_prefs flag\n",
    "    Ouptus : a string with the RMSE and the regularization parameter inputed\n",
    "    \"\"\"\n",
    "    \n",
    "    als = #<>\n",
    "    model = als.fit(#<>)\n",
    "\n",
    "    predictions = model.transform(#<>)\n",
    "    evaluator = #<>\n",
    "\n",
    "    rmse = evaluator.evaluate(#<>)\n",
    "    print(\"regParam={}, RMSE={}\".format(reg_param, np.round(rmse, 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the function created above for several ``reg_param`` values find the best regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regParam=0.01, RMSE=1.08\n",
      "regParam=0.05, RMSE=0.94\n",
      "regParam=0.1, RMSE=0.89\n",
      "regParam=0.15, RMSE=0.88\n",
      "regParam=0.25, RMSE=0.9\n"
     ]
    }
   ],
   "source": [
    "for reg_param in [0.01, 0.05, 0.1, 0.15, 0.25]:\n",
    "    train_model(reg_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4\n",
    "\n",
    "With your best regParam try using the `implicitPrefs` flag.\n",
    "\n",
    ">Note that the results here make sense because the data are `explicit` ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regParam=0.1, RMSE=3.23\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 5\n",
    "\n",
    "Retrain the model with your best ``reg_param`` and ``implicit_prefs`` on the entire dataset and save the trained model in the SAVE_DIR directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...training\n",
      "...saving als model\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE (Replace the symbole #<> with your code)\n",
    "\n",
    "## re-train using the whole data set\n",
    "print(\"...training\")\n",
    "als = #<>\n",
    "model = als.fit(#<>)\n",
    "    \n",
    "## save model\n",
    "print(\"...saving als model\")\n",
    "#<>\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 6\n",
    "\n",
    "We now want to use ``spark-submit`` to load the model and demonstrate that you can load the model and interface with it.\n",
    "\n",
    "Following the best practices we created a python script (``recommender-submit.py``) in the **scripts** folder that loads the model, creates some hand crafted data points and query the model. We recommend you to go over this script and make sure you understand it before running it through this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Cedric.Jouan@ibm.com/Documents/AI_Workflow_Entreprise/venvAIW/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "20/09/15 16:54:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "20/09/15 16:54:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "best rated [(260,), (2628,), (1196,), (122886,), (187595,), (179819,), (1210,)]\n",
      "20/09/15 16:54:39 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "20/09/15 16:54:39 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "closest_users                                                                   \n",
      " [(53,), (452,), (413,), (12,), (337,), (93,), (99,), (523,), (389,), (92,), (176,), (169,), (30,), (77,), (1,), (519,), (371,), (52,), (25,), (69,), (515,), (154,), (472,), (486,), (435,), (80,), (364,), (276,), (543,), (475,), (327,), (122,), (584,), (43,), (527,), (267,), (348,), (97,), (46,), (429,), (45,), (355,), (336,), (594,), (544,), (243,), (573,), (340,), (408,), (456,), (210,), (119,), (586,), (42,), (246,), (304,), (458,), (151,), (492,), (107,), (595,), (251,), (171,), (533,), (240,), (106,), (360,), (35,), (186,), (115,), (548,), (464,), (579,), (256,), (344,), (388,), (48,), (498,), (155,), (283,), (540,), (179,), (192,), (71,), (213,), (574,), (56,), (62,), (95,), (375,), (269,), (201,), (589,), (319,), (188,), (305,), (585,), (450,), (164,), (532,), (380,), (66,), (601,), (441,), (512,), (58,), (278,), (303,), (453,), (447,), (284,), (491,), (37,), (528,), (196,), (539,), (239,), (291,), (374,), (236,), (377,), (220,), (568,), (275,), (597,), (572,), (494,), (382,), (505,), (302,), (400,), (244,), (79,), (40,), (511,), (310,), (88,), (273,), (162,), (250,), (536,), (335,), (558,), (529,), (238,), (11,), (554,), (100,), (402,), (537,), (482,), (376,), (495,), (551,), (556,), (82,), (112,), (582,), (128,), (96,), (545,), (258,), (51,), (59,), (417,), (147,), (518,), (72,), (157,), (538,), (228,), (341,), (14,), (130,), (587,), (136,), (580,), (598,), (592,), (569,), (466,), (83,), (531,), (195,), (158,), (321,), (443,), (68,), (215,), (361,), (484,), (367,), (419,), (225,), (477,), (432,), (342,), (459,), (129,), (488,), (578,), (280,), (576,), (407,), (591,)]\n"
     ]
    }
   ],
   "source": [
    "! python ../scripts/recommender-submit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
