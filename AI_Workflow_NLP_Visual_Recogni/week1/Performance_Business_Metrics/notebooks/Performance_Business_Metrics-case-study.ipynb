{
 "cells": [
  {
   "attachments": {
    "ibm-cloud.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ibm-cloud.png](attachment:ibm-cloud.png)\n",
    "\n",
    "The hype surrounding the combination of good data with state-of-the art machine learning can fall short of expectations.  There are many reasons for this, far too numerous to discuss in a single course, but there are some commonalities and trends.  See the white paper [Beyond the hype: A guide to understanding and successfully implementing artificial intelligence within your business](https://www.ibm.com/downloads/cas/8ZDXNKQ4) for a deeper dive into this topic.  This case study will focus on something that we are referring to as the *follow-through*.  \n",
    "\n",
    "The basic idea of the follow-through is to tune, train and deploy your model, then once you have collected some performance data return to the familiar world of data visualization and hypothesis testing to investigate the relationship between model performance (evaluation metrics) and business metrics.\n",
    "\n",
    "One of the reasons there has not been much focus on follow-through is that there are many projects and time is always precious.  The model is in production---okay what is the next project?  For this reason we propose readying your code for that post-performance investigation *before* the model is deployed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import itertools\n",
    "from string import punctuation, printable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import joblib\n",
    "from collections import Counter\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction import text\n",
    "import seaborn as sns\n",
    "\n",
    "if not 'nlp' in locals():\n",
    "    print(\"Loading English Module...\")\n",
    "    nlp = spacy.load('en')\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "LARGE_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=LARGE_SIZE)   # fontsize of the figure title\n",
    "\n",
    "## Suppress all warnings (not to be used during development)\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_DIR = os.path.join(\"..\", \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis\n",
    "\n",
    "\n",
    "AAVAIL has recently enabled comments on its streaming service.  There are a number of data science projects that have become a priority since. Among other projects, the text will soon need to be monitored for automatic removal of inappropriate content.  Users and posts will need to be flagged for human review.  Your objective in this project will be to leverage comments for customer retention.  Following best practices, you are being asked now to build your code base to ensure you are ready when the first week of comments are ready.  Management has made the specific ask that they want you to monitor the relationship between your model's performance and a customer retention business metric.  \n",
    "\n",
    "As a first pass we are going to perform text classification for customer retention. The movie comments data set with sentiment as a target is a perfect data set to start building a code base.  We are going to give several hints about how you could improve model performance as there are many options when it come to representing your text.  Once your have iterated with respect to transforms and models you will pass the model pipeline to a special function that will simulate model performance **and**  business performance for nine months.  Finally you will create a visualization to help investigate and monitor the relationship between the two.\n",
    "\n",
    "## Outline\n",
    "\n",
    "\n",
    "1. Optimize a text classification pipeline to be deployed for use\n",
    "2. Iterate on and tune the model pipeline\n",
    "3. Use visualization techniques to relate the evaluation metrics to the business metrics\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "In order to perform these tasks we have built a dataset combining two datasets: The AAVAIL stream dataset that summarizes the stream history of 1000 customers from 2018-2019, and the movie review dataset from [nltk_data](http://www.nltk.org/nltk_data) that contains movie reviews with their corresponding sentiment labels (1 if the review is positive and 0 if the review is negative). This combined dataset has 17695 rows (one row per stream session) and 8 columns:\n",
    "* <u>customer_id</u> : The id of the customer that generated this stream.\n",
    "* <u>stream_id</u> : The id of the stream.\n",
    "* <u>date</u>  : The date of the stream.\n",
    "* <u>invoice_item_id</u> : An indication of the type of subscription of the customer.\n",
    "* <u>subscription_stopped</u> : Boolean variable equal to 1 if the customer stopped it's subscription after this stream and 0 otherwise.\n",
    "* <u>comments</u> : A comment that the customer left after this stream. NaN if the customer didn't write a comment.\n",
    "* <u>sentiments</u>  : The actual sentiment of the comment. NaN if the customer didn't write a comment.\n",
    "* <u>M-Y</u> : The month and year of the stream (this column is redundant with the date column but can be used to aggregate the data by month).\n",
    "\n",
    "We built this data by imputing reviews and their sentiment labels from the movie reviews dataset to the AAVAIL streams dataset. The format of these data is very close to the real dataset that the AAVAIL API will return once the comment feature is deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, \"simulated_user_comments.csv\"))\n",
    "\n",
    "# we create two lists, X and y that contains the user comments and the corresponding sentiments, respectively.\n",
    "X = df[~df['comments'].isna()]['comments'].tolist()\n",
    "y = df[~df['sentiments'].isna()]['sentiments'].tolist()\n",
    "target_names = ['neg', 'pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1\n",
    "\n",
    "Before jumping to the preprocessing and the modeling phase, let's perform some EDA on the text data. Create a corpus_summary function that print statements and visualization to summarize the data. Two useful metrics are the number of different words in the full corpus and the number of words per comments but feel free to create your own metrics to summarize this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (Replace the #<> symbols by your code)\n",
    "def plot_corpus_summary(corpus):\n",
    "    #<>\n",
    "    \n",
    "plot_corpus_summary(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2\n",
    "\n",
    "Process the data.  There are many options to consider when you process the tokens from a \n",
    "corpus of text.  These are some of the questions you might want to ask?\n",
    "\n",
    "* Which stop words do I include?\n",
    "* Which stemmer/lemmatizer is best?\n",
    "* Which n-grams do I include?\n",
    "* Do I filter based on frequency min an max?\n",
    "\n",
    "There are many ways to process tokens (words, dates, emojis etc).  NLTK is often used to pre-process text data before the tokens are vectorized.  Generally, the tokens are modified via [stemming or lemmatization](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html).  The next code block provides a lemmatization function that makes use of the library [spaCy](https://spacy.io/).  You will need to install it and download the English language reference material as follows.  Stopwords are words that are very common or otherwise irrelevant we use a default list here, but it is an important part of NLP pipelines that needs to be customized for the subject area. \n",
    "\n",
    "Make sure spaCy is installed and that you downloaded an English language model for the package.\n",
    "\n",
    "```bash\n",
    "~$ pip install spacy\n",
    "~$ python -m spacy download en\n",
    "```\n",
    "\n",
    "Use the following function to process your data into into a clean corpus. Note that this may take a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "STOPLIST = text.ENGLISH_STOP_WORDS\n",
    "STOPLIST = set(list(STOPLIST) + [\"foo\"])\n",
    "\n",
    "def lemmatize_document(doc, stop_words=None):\n",
    "    \"\"\"\n",
    "    takes a list of strings where each string is a document\n",
    "    returns a processed list of strings\n",
    "    \"\"\"\n",
    "    \n",
    "    if not stop_words:\n",
    "        stop_words = set([])\n",
    "  \n",
    "    ## Ensure working with string\n",
    "    doc = str(doc)\n",
    "\n",
    "    # First remove punctuation form string\n",
    "    if sys.version_info.major == 3:\n",
    "        PUNCT_DICT = {ord(punc): None for punc in punctuation}\n",
    "        doc = doc.translate(PUNCT_DICT)\n",
    "\n",
    "    # Remove unicode\n",
    "    clean_doc = \"\".join([char for char in doc if char in printable])\n",
    "            \n",
    "    # Run the doc through spaCy\n",
    "    doc = nlp(clean_doc)\n",
    "\n",
    "    # Lemmatize and lower text\n",
    "    tokens = [re.sub(\"\\W+\",\"\",token.lemma_.lower()) for token in doc ]\n",
    "    tokens = [t for t in tokens if len(t) > 1]\n",
    "    \n",
    "    return ' '.join(w for w in tokens if w not in stop_words)   \n",
    "    \n",
    "## Example usage\n",
    "corpus = ['\"You can fool some of the people all of the time, and all of the people some of the time, but you can not fool all of the people all of the time\". -- Abraham Lincoln']\n",
    "processed = [lemmatize_document(doc, STOPLIST) for doc in corpus]\n",
    "print(processed[0])\n",
    "processed = [lemmatize_document(doc, None) for doc in corpus]\n",
    "print(\"\\n\"+processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (Replace the #<> symbols by your code)\n",
    "\n",
    "# In order to avoid having to preprocess the data everytime we want to run the notebook, we save the new dataframe\n",
    "# with the new column processed_comments.\n",
    "\n",
    "saved_data_filename =  os.path.join(DATA_DIR, \"simulated_user_comments_processed.csv\")\n",
    "if not os.path.exists(saved_data_filename):\n",
    "    df['processed_comments'] = #<> (Hint : consider using the Apply method of the DataFrame pands object)\n",
    "    df.to_csv(saved_data_filename, index=False)\n",
    "else:\n",
    "    print(\"loading {} from file\".format(saved_data_filename))\n",
    "    df = pd.read_csv(saved_data_filename)\n",
    "\n",
    "processed_corpus = #<>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 3\n",
    "\n",
    "Using the function that you created in Question 1, summarize the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 4\n",
    "\n",
    "A [bag-of-words model](https://en.wikipedia.org/wiki/Bag-of-words_model) is a representation of text.  A document or sentence is represented as numeric counts of the individual words, without considering grammar and punctuation.  Even the word order is ignored unless you expand your feature matrix with [n-grams](https://en.wikipedia.org/wiki/N-gram).\n",
    "\n",
    "The most common type matrix derived from the bag-of-words representation **term frequency (TF)**, which is the number of times a token appears in the text.  Another useful matrix is the [term frequency-inverse document frequency (tf-idf)](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) matrix. There are variations on tf-idf and in general these derived matrices can be thought of as *transforms* that can be optimized in an iterative fashion.\n",
    "   \n",
    "Finish the pipeline with a naive Bayes classifier to compare transforms\n",
    "\n",
    "Naive Bayes approaches are a commonly used base model for text\n",
    "classification.\n",
    "\n",
    "There are several types of Naive Bayes model.\n",
    "\n",
    "* Gaussian: It is used in classification and it assumes that features follow a normal distribution.\n",
    "* Multinomial: It is used for discrete counts.\n",
    "* Bernoulli: The binomial model is useful if your feature vectors are binary (i.e. zeros and ones).\n",
    "* Complement: CNB is an adaptation of the standard multinomial naive Bayes (MNB) algorithm that is particularly suited for imbalanced data sets\n",
    "\n",
    "In the next coding cell, we split the dataset into a test set and a training set. Then, you will have to create a text classification pipeline to predict the sentiment of the comments. The first part of the pipeline should transform the processed text to a vector representation, the second part is the classifier estimator. In this question we ask you to use one of the Naive Bayes model presented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some additional EDA allowed us to observe that the first month and last month of the data are incomplete.\n",
    "# Because we want to link the model's impact on the churn rate at a monthly level, \n",
    "# we remove the last month and the first month of the analysis.\n",
    "\n",
    "# Moreover, in order to better test the future impact of our model we take as test set the last 3 complete \n",
    "# months of the dataset and use the rest of the data for the training set.\n",
    "\n",
    "df_test = df[df['M-Y'].astype(str).isin(['2019-08', '2019-07', '2019-06'])].copy(deep=True)\n",
    "df_train = df[~df['M-Y'].astype(str).isin(['2019-08', '2019-07', '2019-06', '2019-09', '2018-01'])].copy(deep=True)\n",
    "\n",
    "# we extract from these two datasets the comments and the sentiment labels which are our independent \n",
    "# and dependent variables, repectively.\n",
    "def create_sentiment_data(df):\n",
    "    X = df.dropna()['processed_comments']\n",
    "    y = df.dropna()['sentiments']\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = create_sentiment_data(df_train)\n",
    "X_test, y_test = create_sentiment_data(df_test)\n",
    "\n",
    "print(\"---------------------------\")\n",
    "print(\"train\", sorted(Counter(y_train).items()))\n",
    "print(\"test\", sorted(Counter(y_test).items()))\n",
    "print(\"targets\", target_names)\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE (Replace the #<> symbols by your code)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "time_start = time.time()\n",
    "pipe1  = #<>\n",
    "param_grid1 = #<>\n",
    "grid1 = #<>\n",
    "grid1.fit(#<>)\n",
    "y_pred = grid1.predict(#<>)\n",
    "print(\"train time\", time.strftime('%H:%M:%S', time.gmtime(time.time()-time_start)))\n",
    "print(classification_report(#<>))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 5\n",
    "\n",
    "See if you can beat the base model. Try other classifiers and other vectorization methods to beat the pipeline that we trained in the previous question\n",
    "(HINT: try using the SGDClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 6\n",
    "\n",
    "Now that you have a created a decent classifier, we want to investigate the relation between our predicted sentiment score and the churn rate.\n",
    "\n",
    "First you should create a dataframe that summarizes the number of churn per month, the average real sentiment, and the predicted sentiment per month. Then, as you would as part of EDA, you will investigate the relationship between the sentiment and the business metric. At a minimum, the investigation should involve visualization, but hypothesis testing and/or statistical models could also be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we add the prediction to the train and test datasets.\n",
    "df_test['sentiment_pred']=np.nan\n",
    "idxs = df_test[~df_test['comments'].isna()]['sentiment_pred'].index.tolist()\n",
    "for i, idx in enumerate(idxs):\n",
    "    df_test.loc[idx, 'sentiment_pred'] = y_pred[i]\n",
    "    \n",
    "df_train['sentiment_pred']=np.nan\n",
    "idxs = df_train[~df_train['comments'].isna()]['sentiment_pred'].index.tolist()\n",
    "for i, idx in enumerate(idxs):\n",
    "    df_train.loc[idx, 'sentiment_pred'] = y_pred_train[i]\n",
    "    \n",
    "    \n",
    "def create_visu(x):\n",
    "    \"\"\"\n",
    "    This function computes the aggregated metrics\n",
    "    Input : A group dataframe of the df_train or df_test dataframe grouped by M-Y\n",
    "    Output : A pandas series with the following 3 aggregated metrics for this month :\n",
    "            - The average number of actual positive comments\n",
    "            - The average number of predicted positive comments\n",
    "            - The total number of churn\n",
    "            \n",
    "    \"\"\"\n",
    "    sentiment = x[~x['comments'].isna()]['sentiments'].mean()\n",
    "    sentiment_pred = x[~x['comments'].isna()]['sentiment_pred'].mean()\n",
    "    churn = x['subscription_stopped'].sum()\n",
    "    return pd.Series({'sentiment': sentiment, 'sentiment_pred': sentiment_pred, 'churn': churn})\n",
    "\n",
    "df_summary = pd.concat([df_train.groupby('M-Y').apply(create_visu), df_test.groupby('M-Y').apply(create_visu)])\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the relationship between the sentiment and the business metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 7 (Optional)\n",
    "\n",
    "Finally, we want to simulate the business impact that our model would have once implemented to support a marketing strategy. This simulation will allow us to link the performance of our model to the retention metric.\n",
    "\n",
    "##### Marketing strategy :\n",
    "We describe the following simple marketing strategy : Every month, our model predicts the average sentiment score of every subscriber. Then, if the ratio of negative comments over positive comments is greater than a certain threshold for a specific customer, the marketing team will send an incentive to this customer. \n",
    "* <u>Assumption 1</u> : Based on previous marketing campaigns, we assume that the probability that a customer stays after receiving the incentive given that he wanted to un-subscribe in the near future follows a normal distribution with mean 0.6 and standard deviation 0.05.\n",
    "* <u>Assumption 2</u> : The accuracy of our model in the coming months will follow a normal distribution with mean 0.81 and standard deviation 0.02.(based on cross validation across months on the training set).\n",
    "* <u>Assumption 3</u> : The predictive model is only a function of it's accuracy. In other words, we will suppose that the proportions of false positives and false negatives are the equal. (This is a strong assumption but we will see later that it is possible to relax it).\n",
    "\n",
    "The business metric that we will use to evaluate this simulated marketing campaign against the performance of our predictive model is the percent decrease in rate of churn when the strategy is implemented.\n",
    "\n",
    "##### Simulated data:\n",
    "To test this marketing strategy we simulated a dataset based on historical data. These data are very similar to the streams dataset: One row corresponds with one stream. The data has 4 columns:\n",
    "* month\n",
    "* customer_id \n",
    "* subscription_stopped -> whereas the customer stopped his subscription after this stream\n",
    "* sentiment -> boolean variable that gives the sentiment (positive of negative) of a comment that the customer left after this stream.\n",
    "\n",
    "In order to simplify this notebook we already generated this simulated dataset and saved it in the data folder. We will focus here on the implementation of the proposed marketing strategy and visualizing its business impact. Specifically, you'll investigate the relationship between the performance of our model and the retention metric. At a minimum the investigation should involve visualization, but hypothesis testing and/or statistical models could be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we load the simulated data\n",
    "df_simulation = pd.read_csv(os.path.join(DATA_DIR, \"simulation_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy = 0.81\n",
    "\n",
    "\n",
    "# We simulate the accuracy of our model on the comming months\n",
    "simulated_acc = {month:np.random.normal(loc=model_accuracy, scale=0.02) for month in df_simulation['month'].unique()}\n",
    "\n",
    "def simulate_model(x):\n",
    "    \"\"\"\n",
    "    This function simulates the output of the model based on the simulated accuracy.\n",
    "    Input : A group dataframe of df_simulation grouped by month.\n",
    "    Output : A copy of the input dataframe with an additional column that gives the simulated sentiments.\n",
    "    \"\"\"\n",
    "    df_tmp = x.copy()\n",
    "    month = df_tmp['month'].iloc[0]\n",
    "    acc = simulated_acc[month]\n",
    "    df_tmp['simulated_sentiments'] = np.nan\n",
    "    for i in range (len(df_tmp)):\n",
    "        if df_tmp['sentiments'].iloc[i]==1 :\n",
    "            if np.random.random() > acc :\n",
    "                df_tmp['simulated_sentiments'].iloc[i]=0\n",
    "            else :\n",
    "                df_tmp['simulated_sentiments'].iloc[i]=1\n",
    "        elif df_tmp['sentiments'].iloc[i]==0 :\n",
    "            if np.random.random() > acc :\n",
    "                df_tmp['simulated_sentiments'].iloc[i]=1\n",
    "            else :\n",
    "                df_tmp['simulated_sentiments'].iloc[i]=0\n",
    "        else :\n",
    "            pass\n",
    "    return df_tmp\n",
    "df_simulation = df_simulation.groupby('month').apply(simulate_model).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def apply_marketing_policy(x, threshold):\n",
    "    \"\"\" \n",
    "    This function implements the marketing policy and outputs the customers that are selected for an incentive.\n",
    "    Input : A group dataframe of df_simulation for a specific customer_id / the threshold that dicts whereas this\n",
    "    customer should receive an incentive according to the simulated strategy.\n",
    "    Output : 1 if this customer should receive an incentive and 0 otherwise.\n",
    "    \"\"\"\n",
    "    if x['subscription_stopped'].max()>0 :\n",
    "        nb_pos = float(x.dropna()['simulated_sentiments'].sum())\n",
    "        len_ = float(len(x.dropna()))\n",
    "        nb_neg = len_ - nb_pos\n",
    "        ratio = nb_neg/(nb_pos+1)\n",
    "        if ratio > threshold:\n",
    "            return 1\n",
    "        else :\n",
    "            return 0\n",
    "    else :\n",
    "        return 0\n",
    "flaged_customer = df_simulation.groupby('customer_id').apply(lambda x : apply_marketing_policy(x, 0.5))==1\n",
    "\n",
    "\n",
    "def simulate_marketing_output(x):\n",
    "    \"\"\"\n",
    "    This function simulates the output of the marketing strategy on the flagged customers.\n",
    "    Input : A row of the df_simulation dataframe.\n",
    "    Output : the simulated value of subscription stopped for this row.\n",
    "    \"\"\"\n",
    "    if x['subscription_stopped'] == 1: # for efficiency\n",
    "        if flaged_customer[x['customer_id']] : # if the customer has been flagged by the model\n",
    "            if np.random.random() < np.random.normal(0.6, 0.05): # simulates the success of the incentive\n",
    "                return 0\n",
    "    return x['subscription_stopped']\n",
    "\n",
    "df_simulation['simulated_subscription_stopped'] = df_simulation.apply(simulate_marketing_output, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (Replace the #<> symbols by your code)\n",
    "\n",
    "def make_visualization_data(x):\n",
    "    \"\"\"\n",
    "    This function creates the aggregated metrics that we want to vizualize.\n",
    "    Input : One group dataframe of the df_simluation dataframe grouped by month (to see how one of these groups \n",
    "    look like you can use the pandas function get_group() on a DataFrameGroupBy pandas object)\n",
    "    Output : A pandas series with the following aggregated metrics : \n",
    "            - The total number of actuall churn for this month\n",
    "            - The total number of simulated churn for this month \n",
    "            - The total number of actuall positive comments\n",
    "            - The total number of predicted positive comments\n",
    "            - The model's accuracy for this month\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = #<>\n",
    "    churn = #<>\n",
    "    simulated_churn = #<>\n",
    "    sentiment = #<>\n",
    "    predicted_sentiment =  #<>\n",
    "    return pd.Series({'churn':churn, 'simulated_churn':simulated_churn, 'sentiment':sentiment, 'predicted_sentiment':predicted_sentiment, 'accuracy':accuracy})\n",
    "\n",
    "\n",
    "\n",
    "df_summary = df_simulation.groupby('month').apply(make_visualization_data)\n",
    "# The buisness output of the marketing is measured with the percentage deacrease in number of churn per month.\n",
    "df_summary['business_perf'] = 100*(df_summary['churn'] - df_summary['simulated_churn'])/df_summary['churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create visualization and/or statistical tests to investigate the relation between the accuracy of the model and the business performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
